# 算法

## **1.单链表排序**：用冒泡排序实现，链表不支持随机查询，但冒牌排序是每次都会将数组或者链表重新遍历一遍

动图参考：<https://blog.csdn.net/meibenxiang/article/details/92796909?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162631017616780262575684%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=162631017616780262575684&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-92796909.first_rank_v2_pc_rank_v29&utm_term=%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95&spm=1018.2226.3001.4187>

````    c++
typedef struct ListNode{
    int data;
    ListNode* next;
}ListNode;

void selectionSort(ListNode* head){
    ListNode* cur1 = head;
    int len = 0;
    while (cur1 != nullptr)
    {
        cur1 = cur1->next;
        len++;
    }
    ListNode* cur2 = head;
    for(int i = 0; i < len - 1; ++i){
        cur2 = head;
        for(int j = 0; j < len - i - 1; ++j){
            if(cur2->data > cur2->next->data){
                int tmp = cur2->data;
                cur2->data = cur2->next->data;
                cur2->next->data = tmp;
            }
            cur2 = cur2->next;
        }
    }
}
````

## 链表算法问题思路总结

1. 链表无法高效获取长度，不利于随机访问（双指针思路）

2. 链表倒数第k个元素：定义两个指针指向头节点，p,q,先让q移动k个元素，让p，q之间的距离变为k，然后开始同时移动两个指针，当q为null时，q就是倒数第k个节点了

3. 获取链表中间的元素节点：还是q，p两个指针，q每次移动2个节点，p每次移动一个节点，当q为最后一个节点时（q->next!=NULL），p就是中间的节点

4. 判断链表是否有环：q，p双指针，q每次移动两个元素，p每次移动一个元素，如果有环，一定会相遇，如果没有环，q会遇到NULL，之间返回。

## 不借助临时变量交换值

```c++
Void swap(int &a, int &b){
	b = a + b;
	a = b – a;
	b = b – a;
}
```



## 排序算法

空间复杂度 时间复杂度 最坏时间复杂度

1. 冒泡排序： O(1) O(n*n) O(n*n)

2. 选择排序 O(1) O(n*n) O(n*n)

3. 快速排序 O(logn) O(nlogn) O(n*n)

4. 堆排 O(1) O(nlogn) O(nlogn)

```c++
//智能指针
template<typename T>
class SmartPointer{
    private:
    T* p_;
    size_t* count_;
    public:
    SmartPointer(T* ptr = nullptr) : p_(ptr){
        if(p_){
            count_ = new size_t(1);
        }
    }

    SmartPointer(const SmartPointer& ptr){
        p_ = ptr.p_;
        count_ = ptr.count_;
        (*count_)++;
    }

    SmartPointer operator=(const SmartPointer& ptr){
        if(p_ == ptr.p_){
            return *this;
        }
        if(p_){
            if(--(*count_) == 0){
                delete p_;
                delete count_;
            }
        }
        p_ = ptr.p_;
        count_ = ptr.count_;
        (*count_)++;
        return *this;
    }
    ~SmartPointer(){
        if(--(*count_) == 0){
            delete p_;
            delete count_;
        }
    }
};

//快排
void quickSort(vector<int> &vec, int left, int right){
    if(left > right) return;
    int base = vec[left];
    int i = left, j = right;
    while(i < j){
        while(vec[j] >= base && i < j)
            --j;
        while(vec[i] <= base && i < j)
            ++i;
        if(i < j)
            swap(vec[i], vec[j]);
    }
    vec[left] = vec[i];
    vec[i] = base;
    quickSort(vec, left, i - 1);
    quickSort(vec, i + 1, right);
}

//堆排
//下标为i的节点的父节点：(i - 1) / 2
//下标为i的节点的左节点:(i * 2) + 1
//下标为i的节点的右节点:(i * 2) + 2
void heapify(vector<int> &vec, int length, int i){
    int largest = i;
    int lson = (i * 2) + 1;
    int rson = (i * 2) + 2;
    if(lson < length && vec[largest] < vec[lson])
        largest = lson;
    if(rson < length && vec[largest] < vec[rson])
        largest = rson;
    if(largest != i){
        swap(vec[largest], vec[i]);
        heapify(vec, length, largest);
    }
}

void head_sort(vector<int> &vec, int lenth){
    //创建堆
    for(int i = lenth / 2 - 1; i >= 0; --i)
        heapify(vec, lenth, i);
    for(int i = lenth - 1; i > 0; --i){
        swap(vec[i], vec[0]);
        heapify(vec, i, 0);
    }
}

//冒泡排序

void bubbleSort(vector<int> &vec) {
int len = vec.size();
for (int i = 0; i < len - 1; ++i) {
for (int j = 0; j < len - 1 - i; ++j)
if (vec[j] > vec[j + 1])
swap(vec[j], vec[j + 1]);
}
}

//选择排序
void selectionSort(vector<int>& vec) {
int len = vec.size();
int minIndex;
for (int i = 0; i < len - 1; ++i) {
minIndex = i;
for (int j = i + 1; j < len; ++j) {
if (vec[j] < vec[minIndex])
minIndex = j;
}
swap(vec[i], vec[minIndex]);
}
}
```

# 计算机网络
## Tcp/ip协议，以及每层的传输协议

OSI7层模型：

应用层(提供用户接口)：FTP, SNMP HTTPS, Telent,SSH

表示层(数据格式转换)：SSL/TLS,JPEG，ASII

会话层（维持会话连接）：PPTP,RPC

传输层(可靠、不可靠传输)：TCP, UDP，端到进程间的通信，提供数据传输服务

网络层（IP地址，路由）：IP, ICMP, IGMP，ARP ，端到端通信

数据链路层（mac地址，帧传输）：ethernet（以太网），vlan，mac 设备到设备通信

物理层（物理传输介质）：光纤，电缆，无线信号

Tcp/ip四层模型：应用层，传输层，网络层，数据链路层&物理层

## ip地址格式

1. 10.0.0.0-10.255.255.255属于私有地址，不能用于公网上

2. 举例192.168.1.255/24，24指的是子网掩码255.255.255.0，前24位为网络号，剩余8位为主机号，子网掩码决定网络范围，主机号全为0（指二进制）为子网，主机号全为1（指二进制）为子网的广播地址。255.255.255.255是所有的主机的广播地址，所有网络上的设备都能接受。

3. A，b，c，d，e类ip地址的区间范围

| **类别** | **范围（第一段）** | **默认子网掩码** | **网络-主机位** | **用途** |
|:---|:---|:---|:---|:---|
| **A 类** | 1.0.0.0 - 126.0.0.0 | 255.0.0.0 (/8) | 1字节网络号 + 3字节主机号 | **大规模网络**（如 ISP） |
| **B 类** | 128.0.0.0 - 191.255.0.0 | 255.255.0.0 (/16) | 2字节网络号 + 2字节主机号 | **中等规模网络** |
| **C 类** | 192.0.0.0 - 223.255.255.0 | 255.255.255.0 (/24) | 3字节网络号 + 1字节主机号 | **小型网络（企业、家庭）** |
| **D 类** | 224.0.0.0 - 239.255.255.255 | **无子网掩码** | **用于多播（Multicast）** | **组播地址** |
| **E 类** | 240.0.0.0 - 255.255.255.255 | **无子网掩码** | **保留（实验用途）** | **未来用途** |

## http状态码

1. 200：请求成功，用于get，post。

2. 301：永久移动，请求的资源已经被永久移动到新的url上面了，返回新的url，并自动刷新到新的url上。

3. 302：临时移动，资源只是被临时移动，应继续使用原先的url

4. 401：请求验证用户身份

5. 403：服务器拒绝执行请求

6. 408：服务器等待客户端发送请求时间过长，超时。

7. 499：客户端被关闭，可能服务器处理时间过长 ，不耐烦了。

8. 500：服务器内部错误，无法完成请求。

9. 502：作为网关或者代理工作的服务器程申请请求时，远程服务器返回一个无效响应

## 搜索百度，过程，dns解析过程

1. 输入url，dns会把url转换成ip地址，dns会查询本地有没有缓存，没有缓存，再去查操作系统hosts文件，没有再询问本地dns服务器，还是没有，<u>本地dns服务向域名根域名服务器发送查询请求，根域名返回一级域名，然后再往一级域名发出查询请求……直到得到ip地址</u>（这个叫递归查询，还有个是迭代查询），然后要建立http连接，http生成get请求报文，报文发送给传输层

2. http是基于tcp的。tcp会把报文分片发给网络层

3. 网络层通过ip协程将报文在路由器中发送。

4. 如果在同一个网段，是会通过数据链路层的arp协议进行寻址传输的。

## Tcp如何保证可靠

1. 序列号，确认号

2. 超时重传：如果发送方没收到确认应答，过一段时间会重传。

3. 拥塞控制

   一开始，发送发维持一个拥塞窗口cwnd，还有一个慢开始门限ssthresh，当cwnd小于慢开始门限，慢开始算法，指数增长，cwnd大于了慢开始门限，采用拥塞避免算法，常数增长。

   如果这时，网络拥塞，慢开始门限ssthresh被设置为阻塞时cwnd的一半，cwnd重新开始增长

   这当中有个快重传和快恢复，如果网络阻塞时，连续收到3次重复确认，就表明当前网络环境还可以，直接将cwnd设置为慢开始门限，然后采用拥塞避免算法。

## TCP 粘包和拆包的原因

**（1）粘包原因**

> **发送端**：

- 应用层写入数据过快，TCP 会合并多个小数据包一起发送，提高网络利用率。

- Nagle 算法启用时，小数据可能会被合并到一个 TCP 报文中。

> **接收端**：

- 接收端 recv() 读取数据不及时，导致多个 TCP 报文堆积在缓冲区，一次性读取多个数据包。

**（2）拆包原因**

- **MTU 限制**：IP 层最大传输单元（MTU，通常 1500 字节）限制了单个 TCP 数据包的大小，超过 MTU 就会被拆分。

- **数据包过大**：应用层发送的数据超过 TCP 发送窗口大小，导致数据被拆分成多个 TCP 报文发送。

- **网络拥塞**：网络层可能对大数据包进行分片传输，接收端需要重组数据。

**（3） TCP 粘包与拆包示例**

假设客户端依次发送 3 个消息：

[Hello] [World] [ChatGPT]

但由于粘包问题，接收端可能收到：

[HelloWorld] [ChatGPT]

或由于拆包问题：

[Hel] [loWor] [ldChatGPT]

## Websocket和http

Websocket通过http进行一次性握手后，建立连接，然后采用帧的方式传输数据，服务器和客户端都可以主动传输数据，无需等待，通过心跳，以及底层tcp定期检测保持连接，并且有断开自动重连功能onclose事件，适用于即时通信，直播弹幕，聊天客服等，但并不能取代http

| **缺点** | **影响** | **解决方案** |
|:---|:---|:---|
| **服务器资源消耗高** | 长连接占用内存、TCP 连接 | 连接池、清理无效连接 |
| **代理和负载均衡兼容性差** | 传统 HTTP 代理不支持 | 使用 Nginx / HAProxy WebSocket 代理 |
| **防火墙可能拦截** | 企业网络可能禁止 | 使用 wss:// 端口 443 连接 |
| **不适合短连接** | HTTP 请求比 WebSocket 高效 | API 用 HTTP，推送用 WebSocket |
| **开发复杂** | 需要自己管理连接 | WebSocket 框架、自动重连 |
| **可靠性问题** | 没有内置消息确认 | 使用 ACK 机制、消息队列 |
| **安全风险** | WebSocket 可能被劫持 | wss:// + Origin 头检查 |

## 网络编程一般步骤

1 服务器端：创建socket， bind绑定端口，ip， listen监听客户端 accept建立连接 read write close

2\. 客户端：创建socket bind绑定端口 write read close

### Tcp连接状态图，以及挥手握手过程

<img src="./images/media/image1.png" style="width:7.54167in;height:6.95833in" alt="20160902203203817" />

客户端的状态变迁：CLOSED-->SYN_SENT-->ESTABLISHED-->FIN_WAIT_1-->FIN_WAIT_2-->TIME_WAIT-->CLOSED

服务器的状态变迁：CLOSED-->LISTEN-->SYN_RCVD-->ESTABLISHED-->CLOSE_WAIT-->LAST_ACK--->CLOSED

| **当前状态** | **触发条件** | **下一状态** | **所属对象** | **发起方** |
|:---|:---|:---|:---|:---|
| **CLOSED** | 客户端应用调用 connect() | **SYN_SENT** | **客户端** | **客户端主动** |
| **LISTEN** | 服务器收到 SYN | **SYN_RECEIVED** | **服务器** | **客户端主动** |
| **SYN_SENT** | 收到 SYN + ACK | **ESTABLISHED** | **客户端** | **服务器响应** |
| **SYN_RECEIVED** | 收到 ACK | **ESTABLISHED** | **服务器** | **客户端响应** |
| **ESTABLISHED** | 客户端应用调用 close()，发送 FIN | **FIN_WAIT_1** | **客户端** | **客户端主动** |
| **FIN_WAIT_1** | 服务器收到 FIN 并发送 ACK | **FIN_WAIT_2** | **客户端** | **服务器响应** |
| **FIN_WAIT_1** | 服务器直接发送 FIN + ACK | **CLOSING** | **客户端** | **服务器主动** |
| **FIN_WAIT_2** | 收到 FIN | **TIME_WAIT** | **客户端** | **服务器主动** |
| **CLOSE_WAIT** | 服务器收到 FIN，等待应用层处理 | **CLOSE_WAIT** | **服务器** | **客户端主动** |
| **CLOSE_WAIT** | 服务器应用层调用 close()，发送 FIN | **LAST_ACK** | **服务器** | **服务器主动** |
| **LAST_ACK** | 收到 ACK | **CLOSED** | **服务器** | **客户端响应** |
| **CLOSING** | 收到 ACK | **TIME_WAIT** | **客户端** | **服务器响应** |
| **TIME_WAIT** | 经过 2 * MSL（最大报文生存时间） | **CLOSED** | **客户端** | **超时触发** |

| **状态**    | **说明**                                    |
|:------------|:--------------------------------------------|
| CLOSED      | 连接关闭状态（初始状态和最终状态）          |
| LISTEN      | 服务器监听客户端连接                        |
| SYN_SENT    | 客户端主动连接，发送 SYN 请求               |
| SYN_RCVD    | 服务器收到 SYN，回复 SYN + ACK              |
| ESTABLISHED | 连接建立成功，数据传输进行中                |
| FIN_WAIT_1  | 客户端主动关闭，发送 FIN                    |
| CLOSE_WAIT  | 服务器收到 FIN，等待应用程序处理            |
| FIN_WAIT_2  | 客户端收到 ACK，等待服务器 FIN              |
| LAST_ACK    | 服务器发送 FIN，等待 ACK                    |
| TIME_WAIT   | 客户端收到 FIN，发送 ACK 并等待 2*MSL 时间 |
| CLOSED      | 连接完全关闭                                |

<img src="./images/media/image2.png" style="width:5.87083in;height:3.00347in" alt="850de5c566ae60989f45cff4b1aad94c" /><img src="./images/media/image3.png" style="width:4.98681in;height:2.93056in" alt="0dc25c2e6ae3de02cc4039553165d8cf" />

Tcp三次握手是保证连接的可靠性，四次挥手是保证数据发送完了再断开连接，避免数据丢失

拥塞控制：慢启动，拥塞避免，快速重传，快速恢复

慢启动：发送方维护拥塞窗口（cwnd），初始值为1，每收到一个ack就指数增长 ，直到到达慢启动阈值（ssthresh)，进入拥塞避免阶段

拥塞避免：当cwnd超过ssthresh时，不再指数增长，改为线性增长，知道发生丢包，或者超市重传

快速重传：当发送方，连续接受到3个相同ack，就立即重传数据包。

快速恢复：指的是当重传的时候，不再慢启动，cwnd不再从1开始，直接从ssthresh的一半开始

滑动窗口：防止发送发过快的发送数据，导致接受方处理不过来，主要维护两个缓存区，发送窗口（发送方允许发送但未确认的数据范围，值：swnd = min(cwnd, rwnd)），和接受窗口（接收方可以接收的最大数据量（值由 rwnd 设定，TCP 头部的 Window 字段通知发送方当前的 rwnd））

Nagle 算法：减少**小数据包的数量**，提高传输效率，当有多个小数据包，会合并成一个大包发送，提高吞吐量，适用于日志数据

TCP_NODELAY：禁用 Nagle 算法，**立即发送数据包**，降低延迟，不等待ack，数据实时发送，适用于游戏

## Https加密传输过程

http端口80，https端口443

1. 两个概念： 对称加密：加密解密用的都是同一个密钥

> 非对称加密：一个公钥，一个密钥，公钥任何人都拿的到，自己会有一份独一的密钥，其他人不可见，公钥加密，传送数据，然后用自己的密钥解密。

证书：为了确保公钥是从服务器发来的，且是货真价实的。

https除了建立3次握手，再3次握手之前还需要进行SSL加密握手，速度会慢很多。

2. 流程：<img src="./images/media/image4.png" style="width:9.575in;height:10.725in" />非对称加密协商，对称加密传输

    1) 认证服务器，开发商在开发浏览器的时候，会在浏览器里面存放一个CA机构证书表，表中记录的那些CA机构证书是值得信任的。客户端发出连接请求，服务器会返回一个由CA机构认证的服务器证书，客户端拿到证书，查询自己的CA表，如果这个CA机构在表中，且服务器证书的信息与当前访问的ip一致，就认为该证书可信，然后从服务器证书中获取服务器的公钥。

    2) 协商会话密钥，客户端和服务端会协商两个会话密钥，一个是客户端往服务端发送数据的会话密钥，另一个是服务端往客户端发送数据的会话密钥，这两个都是对称密钥。客户端通过公钥加密客户端往服务端发送数据的密钥，和自己公钥，然后服务器用自己的私钥解密后，通过客户端的公钥加密服务端往客户端发送数据的密钥，客户端用自己私钥解密。协商的密钥每次都是随机的。

    3) 传输数据，然后客户端和服务端就是通过两个密钥进行传输数据，这样做的好处就是，对称加密比较节约计算资源，能让传输速度更快。

## CDN（内容分发网络）加速

| **关键点**     | **作用**                               |
|:---------------|:---------------------------------------|
| **CDN**        | 通过全球分布的边缘服务器加速内容传输   |
| **边缘服务器** | 靠近用户的缓存节点，减少访问延迟       |
| **缓存机制**   | 通过**强制缓存、协商缓存**减少重复请求 |
| **智能路由**   | 选择**最近的服务器**，优化访问速度     |

CDN 适用于：

- **视频网站（YouTube、Bilibili）**：减少视频加载时间

- **电商网站（淘宝、亚马逊）**：加速图片和商品页面加载

- **游戏加速（Steam、腾讯游戏）**：减少延迟，提高下载速度

- **全球新闻/社交平台（Twitter、Facebook）**：提高数据同步效率

## 负载均衡

### **负载均衡算法对比**

| **算法** | **优点** | **缺点** | **适用场景** |
|:---|:---|:---|:---|
| **轮询（Round Robin）** | 简单易实现，适用于短连接 | 服务器负载可能不均衡 | 适用于 HTTP 短连接 |
| **最小连接（Least Connections）** | 适用于长连接，负载均衡效果好 | 需要额外记录连接数，增加计算开销 | 适用于数据库、WebSocket |
| **哈希（IP Hash）** | 保证同一 IP 请求落在同一服务器，保持会话 | 负载可能不均衡，某些服务器可能压力过大 | 适用于用户会话保持，如支付、认证 |

轮询：请求**依次分配**给服务器，按照**循环**的方式轮流分配。适用于**性能相近**的服务器集群。

最小连接：**优先分配**请求给**当前活跃连接最少**的服务器。适用于**长连接请求**（如数据库查询、WebSocket 连接等）。

哈希：通过**对客户端 IP 进行哈希运算**，决定请求分配到哪台服务器。确保同一 IP 的请求始终分配到同一服务器（**会话保持**）。

# 数据库

## 隔离级别

1. 未提交读：一个事务在提交前，对其他事务是可见的，就是说一个事务可以读到另一个事务还没来得及提交的数据，存在脏读

2. 提交读：一个事务在提交前，对其他事务是不可见的，解决脏读，但在存在不可重复读的问题，在两次查询之间，有事务被提交，两次查询结果不一样

3. 可重复读：同一个事务对一份数据读取的结果总是一致的，解决不可重读读，但存在幻读（两次查询之间，有其他事务对数据进行插入或者删除）（mysql默认）

4. 可串行化：一个事务一个事务处理，这个事务处理完了，下个事务才会开始，速度很慢。

## 数据库处理并发问题

1. 共享锁：类比读锁

2. 排他锁：类比写锁

3. 加锁策略：表锁，对整张表加锁，开销小，并发低 行级锁：对每条一行记录加锁，开销大，并发高

4. InnoDB MVCC：为了不加锁实现的一个机制，在每条记录后面会加两个隐藏列：记录的创建时间，过期时间。在插入删除修改时，通过这两个隐藏列来避免脏读，不可重复读，幻读的问题。

## 数据库事务的一致性

1. 原子性：数据库事务是一个整体，要么成功，要么失败

2. 一致性：数据库事务总是从一个状态变为另一个状态

3. 持久性：事务一旦提交，造成的修改是永久性的

4. 隔离性：事务之间彼此相互不影响

## 索引

B+树：b树每一个节点里面存放的是2个数据，b+树每个结点存放的是索引，索引可以放多个，b+树叶子节点存放的是具体数据，最后一层数据再通过一个链表串起来。B+树默认有序，索引速度O(logn)

哈希：哈希索引速度很快O(1)，默认无序，（注意哈希冲突，链地址法解决）

## 数据库引擎

InnoDB：最通用的引擎，支持事务、行级锁，热备份，MVCC，在并发上占优势，系统占用资源多，不支持全文索引，支持外键，索引：b+树，哈希。

MyISAM：默认的引擎，不支持事务、行级锁，有表锁，查询速度很快，系统占用资源少，支持全文索引，不支持外键，索引：b+树。

## 三大范式

1. 第一范式：每一列都要是不可拆分的整体

2. 第二范式：确保每列都要与主键相关

3. 第三范式：确保每列都要与主键直接相关

> 为什么要满足范式：可以使冗余小，结构合理，但不利于查询。

## 索引的底层实现

1. InnoDB建表，并添加了索引：生成的文件.frm文件（建表的语句）和.idb文件（索引文件和数据文件）,聚集索引。

2. Myisam建表，并添加索引：生成.frm文件（建表的语句），.MYD文件（Myisam data 数据文件）和.MYI（Myisam idex索引文件），非集聚索引。

3. Myisam引擎底层（非聚集索引）：建表以主键key建立索引b+树，叶子节点存放具体数据。当为其他字段添加索引，也是建立该索引的b+树，然后叶子节点存放数据。

4. InnoDB引擎底层（聚集索引）：首先会根据主键建立b+树，然后叶子节点存放具体数据，如果其他字段有索引，为这个字段建立索引b+树，但是叶子节点存放的是主键索引的key，要在去主键索引b+树中查找一次，才能找到具体数据。

5. 差异：因为聚集索引和非聚集索引的差距：使Misam查找速度快，浪费更多空间（一般只需查找一次，每个索引都存放着具体数据），InnoDB查找慢一点，但节省空间（一般要查找两次，除了主键索引，其他所有存放的是主键中的索引key）

## 什么情况才需要添加索引

1. 需要频繁更新的数据不利添加索引

2. 区分度不够的索引不利于添加索引（比如性别）

3. 频繁作为查询的字段应该添加索引

# C++语法

## c++11的一些tips

### **1. 局部静态变量初始化的线程安全性**

C++11 标准规定，当多个线程首次同时调用包含局部静态变量的函数时，**初始化过程会被隐式同步**，确保只有一个线程执行初始化代码，其他线程会阻塞直到初始化完成。
这一特性常被称为 **"Magic Statics"**，其实现原理是编译器自动插入双重检查锁（Double-Checked Locking）或原子标记位机制

。例如：

```cpp
// C++11 线程安全的单例模式实现
class Singleton {
public:
    static Singleton& getInstance() {
        static Singleton instance;  // 初始化由编译器保证线程安全
        return instance;
    }
private:
    Singleton() = default;
};
```

此时无需在 `getInstance()` 中手动添加锁或其他同步机制来保护初始化过程

​	局部静态变量初始化的线程安全性

## 模板

### 函数模板

1. 基本声明

```c++
template <typename T>//<class T>
T maxValue(T a, T b)
{
    return (a > b) ? a, b;
}
```

//使用

```c++
int a = maxValue(2, 7);//隐式调用
double b = maxValue<double>(1.1, 2.2);//显示调用
```

2. 多个参数

```c++
template<typename T1, typename T2>
void print(T1 a, T2 b)
{
    cout << a << b << endl;
}
```

3. 设定默认值

```c++
template <typename T = int>
T add(T a, T b) {
    return a + b;
}
```

4. 带非类型参数

```c++
template <typename T, int N>  // N 是非类型模板参数
T add(T a) {
    return a + N;
}
```

```c++
//使用

std::cout << add<int, 5>(10) << std::endl; // 5 + 10 = 15
```

#### 类模板

1. 基本使用

```c++
template <typename T> class Box {
private:
  T m_value;
public:
  Box(T v) : m_value(v) {}
};
```

2. 类模板的非类型参数

```c++
//声明
template <typename T, int SIZE>
class Array {
private:
    T arr[SIZE];
public:
    void set(int index, T value) { arr[index] = value; }
    T get(int index) { return arr[index]; }
};

//使用
Array<int, 5> arr;  // 创建 5 个元素的 int 数组
arr.set(0, 10);
std::cout << arr.get(0);  // 输出 10
```

#### 变量模板

1. 用于定义通用变量。

```c++
template <typename T>
constexpr T pi = T(3.1415926535897932385);
```

#### 别名模板

为模板类型创建别名，简化使用。

```c++
template <typename T>
using Vec = std::vector<T>;
Vec<int> numbers; // 等价于 std::vector<int>
numbers.push_back(42);
```

#### 模板特化

#### 可变参数模板

```c++
template <typename... Args>  // 可变模板参数
void func(Args... args) {
    // 处理 args
}
```

• typename... Args **表示多个模板参数**，可以是任意类型的。

• Args... args **表示多个函数参数**，可接受任意数量的参数。

```c++
// 终止递归的基础函数
void print() {
    std::cout << "结束递归" << std::endl;
}

// 递归函数
template <typename T, typename... Args>
void print(T first, Args... rest) {
    std::cout << first << " ";
    print(rest...);  // 递归调用，展开参数包
}

int main() {
    print(1, 2.5, "Hello", 'A');  
}
```

• print(1, 2.5, "Hello", 'A') 会依次展开：

- print(1, 2.5, "Hello", 'A')

- print(2.5, "Hello", 'A')

- print("Hello", 'A')

- print('A')

- print()（终止递归）

• print() 是递归终止条件，否则编译器会报错。

## c++的锁相关语法

### 1.std::lock_guard和std::unique_lock

​	C++ 标准库中用于管理互斥锁（`std::mutex`）（当然，其他的锁只要满足互斥锁的概念也可以用）的 RAII 类模板,它们的主要目的是确保互斥锁在作用域结束时自动解锁，避免资源泄漏或死锁。

#### std::lock_guard

特点

- 简单易用：构造时锁定互斥锁，析构时自动解锁

- 不可手动解锁：一旦构造，只能再作用域结束自动释放

- 适用于简单场景：用于不用手动管理锁的场景

  ```c++
  std::mutex mtx;
  int shared_data = 0;
  
  void increment(){
      std::lock_guard<std::mutex> lock(mtx);
      ++shared_data;
      //作用域结束自动解锁
  }
  ```

#### std::unique_lock

特点

- 灵活性高：允许手动锁定/解锁互斥锁

- 延迟锁定：可以在构造时不锁定互斥锁，稍后再手动锁定

- 支持移动变量：change与std::condition_variable一起使用

- 可移动：可以通过移动语义转移锁的使用权

  ```c++
  std::mutex mtx;
  int shared_data = 0;
  
  void increment(){
      std::unique_lock<std::mutex> lock(mtx);
      ++shared_data;
      lock.unlock(); //手动解锁
      lock.lock();  //手动上锁
      ++shared_data;
      //作用域自动解锁
  }
  
  //延迟锁定
  void delayed_lock() {
      std::unique_lock<std::mutex> lock(mtx, std::defer_lock); // 构造时不锁定
      // 做一些不需要锁的操作
      lock.lock(); // 手动锁定
      ++shared_data;
      // 作用域结束时自动解锁
  }
  
  //与条件变量一起使用
  #include <condition_variable>
  
  std::condition_variable cv;
  bool ready = false;
  
  void wait_for_ready() {
      std::unique_lock<std::mutex> lock(mtx);
      cv.wait(lock, [] { return ready; }); // 等待条件变量
      ++shared_data;
  }
  
  void set_ready() {
      std::unique_lock<std::mutex> lock(mtx);
      ready = true;
      cv.notify_all(); // 通知等待的线程
  }
  ```

  

## Malloc New

Malloc在堆上申请内存，new在自由存储区上分配内存

Malloc失败返回Null，new失败会抛出异常

Malloc分配空间需要指定大小，new不用指定大小

Malloc不能触发对象的构造函数，new可以触发对象的构造函数

Malloc成功返回的是void*指针，一般需要强转下，new返回对应类型的指针。

## explicit

- `explicit` 只能用于构造函数，不能用于普通成员函数或其他函数。
- 对于单参数构造函数，推荐总是使用 `explicit`，除非有特殊需求需要允许隐式转换。
- 从 C++11 开始，`explicit` 也可以用于转换构造函数和模板构造函数。

## constexpr vs const

| **关键字** | **作用**   | **适用范围**             | **计算时间**     |
|:-----------|:-----------|:-------------------------|:-----------------|
| const      | 只读变量   | **变量、对象**           | 运行时或编译时   |
| constexpr  | 编译时常量 | **变量、函数、类、对象** | **必须是编译时** |

## Static关键词

### 局部static变量

只初始化一次，整个程序声明周期都存在，函数调用后也不会销毁

### 全局static变量

作用域是仅限当前.cpp文件，不会被其他文件访问，比全局变量要好点

### static成员变量

所以对象共同使用同一个静态变量，不属于任何一个对象。并且是在类外部初始化

### Static成员函数

只能访问静态变量，不能访问非静态变量，因为静态成员函数没有this指针，因此不能获取到非静态成员变量，静态函数可以不通过对象实例访问直接类名::函数名就可以访问

## C++特性

1. 多态：在有继承关系的类中，去调同一个函数(调用函数的对象要是指针或者引用，要有虚函数)，c++多态分为静态多态：函数重载，模板函数，动态多态：虚函数

2. 虚析构：设置了虚析构，当用父类指针指向子类时，父类指针销毁，也会调用到子类的析构，如果不是虚析构，就只会调用父类析构

3. 重载：函数名一样，函数参数不一样，返回值没有关系，重写：子类继承父类，子类重写父类的虚函数，返回值，函数名，函数参数都一样，内容不一样

4. 仿函数的作用：又叫函数对象，仿函数可以拥有自己的成员变量，有更好的速度。

5. 深拷贝，浅拷贝：用一个指针指向在堆上开辟的空间，如果之间将指针赋值，只是将这个堆上空间的地址给另一个指针，如果之前的指针释放了，那复制后的指针也就失去了那片内存，这是浅拷贝，只是单纯的赋值，深拷贝应该是要把要重新开辟堆上地址，然后把内容拷贝过去，再把这个地址赋给一个指针。

## mutable和volatile

volatile：表示编译器不会对volatile声明的变量优化，从而让它可以稳定访问某一个值

mutable：mutable声明的变量表示一直处于可变的的状态，即使在const函数中。

## Inlie

Inlie函数，有点类似于宏，inlie被声明后，在被调用的地方进行代码展开，省去了函数栈的操作，inlie保留了函数的性质，在类中声明并定义可以访问类的变量，可以被调试，宏不行。

Inlie只是建议，是否内联要看编译器。

## 智能指针

1. Shared_ptr：有共享的概念，内部有个引用计数，会记录当前有多少个Shared_ptr指向这个对象，可以通过unique_ptr,weak_ptr来构造，也可以自己new。Reset成员函数，使引用计数减一，作用放弃当前智能指针

2. Weak_ptr：这个主要是配合shared_ptr使用的，对已经被shared_ptr引用的对象，再加weak_ptr，不会使引用计数加一。不能直接通过weak_ptr去访问对象方法。要转换成shared_ptr才可以。

3. Unique_ptr：独占指针指针，一个对象只能有一个unique_ptr实例，只能指向一个实例，且不允许更改

| **智能指针** | **所有权** | **是否可共享** | **是否可拷贝** | **是否支持引用计数** | **适用场景** |
|:---|:---|:---|:---|:---|:---|
| unique_ptr | 独占 | 否 | 否（只能移动） | 否 | 资源独占，防止内存泄漏 |
| shared_ptr | 共享 | 是 | 是 | 是 | 资源共享，多个对象持有 |
| weak_ptr | 观察 | 是 | 是 | 否（不增加计数） | 避免 shared_ptr 循环引用 |

shared_ptr 可能导致循环引用

Eg:

```c++
std::shared_ptr<A> a = std::make_shared<A>();
std::shared_ptr<B> b = std::make_shared<B>();
a->b_ptr = b;
b->a_ptr = a; // ⚠️ 形成循环引用，内存泄漏
```

## 类型转换

1. Const_cast：去掉const限定
2. Static_cast：主要是向上转换，加const， void*转其他类型，也可用于多态向上转换（子类往基类转换）
3. Dynmic_cast：主要用于多态向上转换，向下转换（基类往子类转化）
4. Reinterpret_cast：什么都可以转，但是不安全。

## lambda表达式

语法：[捕获列表] (参数列表) -> 返回类型 { 函数体 }

### 1.**捕获列表**

​	捕获列表用于指定lambda表达式是否可以访问外部变量

```c++
[]			//不捕获外部变量
[=]			//按值捕获外部所有变量
[&]			//按引用捕获外部所有变量
[x, &y]		//按值捕获外部x，按引用捕获外部y

int main() {
    int N = 100, M = 10;
    auto g = [N, &M](int i) {
        M = 20;
        return N * i;
    };
    std::cout << g(10) << std::endl; // 输出 1000
    std::cout << M << std::endl;    // 输出 20
    return 0;
}
```

### 2. **参数列表**

​	参数列表与普通函数的参数列表类似，用于传递参数给 Lambda 表达式。如果没有参数，可以省略 （）

### 3. **返回类型**

​	返回类型可以显式指定，也可以由编译器自动推断。如果函数体只有一条 `return` 语句，可以省略返回类型。

### 4. **函数体**

​	函数体是 Lambda 表达式的执行代码，与普通函数的函数体相同。

## const修饰词

Const修饰的对象，只能调用const函数，不能去调用非const修饰的函数

当一个对象被声明为 const，意味着它的内部数据**不能被修改**。而 **非** const **成员函数** **可能会修改成员变量**，所以**不能被** const **对象调用**。

const 对象可以调用 static 成员函数，static 成员函数**不依赖于对象实例**，所以const 对象也可以调用 static 成员函数。

<img src="./images/media/image5.png" style="width:8.74167in;height:1.875in" />

记忆口诀

• const 在 int **左边** → **修饰** int**，值不可改**。

• const 在 * **右边** → **修饰指针，指针不可改**。

## 指针，二级指针

如果只是声明**对象指针**，而**没有初始化**或**没有通过** new **创建对象**，构造函数**不会被调用**。

指针大小在32位的操作系统大小都是4字节，64为8字节

### 二级指针

```c++
int a = 10;
int *p = &a;  	//一级指针，指向a的地址
int **pp = &p; 	//二级指针，执行指针p的地址
cout<<**pp;		//输出10
```

#### 数组

数组名是常量指针：int arr[5];    arr等价于&arr[0]  (指向第一个元素的地址)

内存是连续的，指针可以累加访问

```c++
int arr[3]={1,2,3};
int *p = arr;		//p指向arr[0]
cout << *(p + 1)	//输出2,等价于arr[1]
```

### 二维数组,和指针数组

指针数组可以模仿二维数组（每行长度是可变长的） ：int * prtArr[3]; (包含3个int*类型元素的数组  int arr[ ][3]，是可变长的 )

```c++
int a[] = {1，2}; b[] = {3, 4, 5}; c[] = {6, 7};
int* ptrArr[3] = {a, b, c};  	// 指针数组
cout << *ptrArr[1][2];             // 输出5
```

### 数组退化为指针

- 当数组作为函数参数传递时，会退化为指针：

  ```
  void func(int arr[]) {  // 实际是 int* arr
      cout << sizeof(arr); // 输出指针大小（如 8 字节）
  }
  ```

- 二维数组传递时需指定列数，或使用指针的指针：

  ```c++
  void func(int arr[][4], int rows);   // 传入的是静态二维数组，应该明确指定数组的第二维大小
  void func(int** arr, int rows);     // 适用于动态分配的二维数组，列如传入的数组是这样定义的int** arr = new int*[3]
  ```

### 指针数组与二级指针的转换

```c++
int * ptrArr[3];
int **pp = prtArr;	// 合法，ptrArr 退化为 int**
```



## 与或运算

只支持整数，不支持浮点数，指针和bool则是不推荐使用与或运算

## 结构体对齐规则

结构体对齐是可以提高cpu的访问效率

对其规则：

1. 结构体的总大小必须是结构体中 "最大基本类型大小" 的整数倍

2. 每个成员变量的存储地址必须是其类型大小的整数倍

    这句话举例解释Eg：

    ```c++
struct Example {
    	char c; // 1 字节
	int i; // 4 字节
    };
    ```

Char c ，char对齐要求是1的倍数，偏移1个字节，可以从结构体偏移量为0开始存储
    
Int i ，int对齐要求必须是4的倍数，而前面偏移只有1个字节，不满足，需要插入3个字节的padding来到偏移4个字节
    

3. 可能会插入填充字节（padding）来满足对齐规则

## 右值引用的作用

右值引用可以给右值续命，让它能被保存下来，T&& t右值引用，在被赋值之前类型是不确定的，如果给一个左值初始化那它就是左值，被一个右值初始化那它才是右值，

A a = GetA();
A GetA()
{
return A();
}

通过这个特性，可以再有深拷贝的类中，加一个移动构造，GetA()返回的是一个右值，如果是深拷贝中，GetA()返回会调用一次深拷贝，然后A a赋值再调用一次深拷贝，如果是移动构造（就是参数为右值引用，因为是右值，资源会被销毁，直接把变指针指向就可以了），不会造成深拷贝的额外开销。

https://www.cnblogs.com/qicosmos/p/4283455.html

## 移动构造

拷贝构造一般为深拷贝，需要拷贝的指针也要重新开辟一块内存，去存储数据。

移动构造的被拷贝值一般是要消亡的对象，如右值，就可以直接把它的内存

## 如何判断大小端

大端：低位存放在高位地址

小端：低位存放在低位地址

举例：0x123456 如果存放方式为123456就是大端机器。 如果存放方式为654321就是小端机器

如何判断：

联合体union，因为联合体所有数据成员共享一块地址，联合体的最大地址宽度就是最大的成员变量。而且总是按照从低位地址到高位地址开始存储的

 ```c++
    union p{
    	int a;
    	char b;
    };
      
    int panduan_2(){
    	p p1;
    	p1.a = 1;
    	return p1.a==p1.b;
    }
 ```

解释：让a = 1, a有4个字节，再让b去访问a中的一个字节，因为联合体都是从低位地址开始存储的，如果是大端机器，b就会先访问到a的高位，结果为0

如果是小端机器，b就会先访问到a 的低位，结果为1。

## Std::move std::forward

Std::move: 将左值或者右值转换成右值引用

Std::forward: 将参数原封不动的穿个下个参数，是左值传递还是左值，是右值传递还是右值。

# 操作系统（OS)

## 编译器运行的几个阶段：C++ **编译器运行的几个阶段**主要包括**预处理、编译、汇编、链接**四个主要阶段

### 预处理阶段（Preprocessing）

文件扩展名：.cpp → .i（预处理后的代码）

主要任务：

处理 \#include 头文件

处理 \#define 预处理指令（宏展开）

处理 \#if/#ifdef/#ifndef 预处理指令

删除注释

### 编译阶段（Compilation）

文件扩展名：.i → .s（汇编代码）

主要任务：

词法分析（Lexical Analysis）：将代码拆分成标记（Tokens）

语法分析（Syntax Analysis）：检查代码语法结构

语义分析（Semantic Analysis）：检查类型、作用域、运算是否合法

生成中间代码（如 AST：抽象语法树）

生成汇编代码

### 汇编阶段（Assembly）

文件扩展名：.s → .o（目标文件）

主要任务：

将汇编代码转换为机器码（二进制指令）

生成目标文件（.o 或 .obj）

### 链接阶段（Linking）

文件扩展名：.o → 可执行文件（a.out / .exe）

主要任务：

符号解析：找到所有函数、变量的定义

库链接：

静态库（.a / .lib）

动态库（.so / .dll）

合并多个目标文件，生成最终可执行文件

### 程序执行（Execution）

当可执行文件运行时，涉及：

加载（Loading）：操作系统加载可执行文件到内存

动态链接（Dynamic Linking）：加载动态库（.so / .dll）

运行（Execution）：执行代码

## SIMD 向量化简介

1. 什么是 SIMD？

SIMD（Single Instruction, Multiple Data，单指令多数据流）是一种**并行计算**技术，它允许 CPU **使用一条指令同时处理多个数据**。现代 CPU **几乎都支持 SIMD 指令集**（如 SSE、AVX、NEON 等），用来加速数学计算、图像处理、物理模拟等场景。

2. SIMD 向量化的作用

    在普通的逐个数据处理（**标量计算**）中，CPU **每次只能对一个数据执行一个操作**，例如：

```c++
for (int i = 0; i < N; i++) {  
    a[i] = b[i] + c[i]; // 每次只能处理一个 a[i]
}
```

如果 N=1000000，这个循环需要 **100 万次加法操作**。

而 **SIMD 向量化** 能够让 CPU **一次性处理多个数据**（如 **4 个或 8 个 float 数值**），从而减少循环次数：

```c++
// 假设 CPU 支持 256 位 AVX 指令，每次可处理 8 个 float
// 伪代码
for (int i = 0; i < N; i += 8) {
a[i:i+7] = b[i:i+7] + c[i:i+7]; // 一次处理 8 个 a[i]
}
```

如果 N=1000000，循环**只需要执行 12.5 万次**，计算速度大大提高！

### 进程，线程可共享的资源

| **资源类型** | **进程内的线程是否共享？** | **不同进程是否共享？** |
|:---|:---|:---|
| **代码段** | ✅ 共享 | ❌ 不共享 |
| **堆（Heap）** | ✅ 共享 | ❌ 不共享（除非使用共享内存） |
| **全局变量 / 静态数据** | ✅ 共享 | ❌ 不共享 |
| **文件描述符** | ✅ 共享 | ❌ 不共享（除非 dup() 传递） |
| **信号处理** | ✅ 共享 | ❌ 不共享 |
| **栈（Stack）** | ❌ 不共享 | ❌ 不共享 |
| **寄存器（Registers）** | ❌ 不共享 | ❌ 不共享 |
| **线程本地存储（TLS）** | ❌ 不共享 | ❌ 不共享 |
| **进程地址空间** | ✅ 共享 | ❌ 不共享 |

🚀 **记住**：线程共享 **代码、堆、全局变量**，但有**自己的栈和寄存器**！

### 同步IO 异步IO

加一点关于互斥和同步的

互斥 ≠ 同步

互斥只保证同一时间只有一个线程访问共享资源，但并不保证多个线程的执行顺序。

同步是更高级的概念，除了互斥，还可以用 条件变量（Condition Variable）、信号量（Semaphore） 实现。

I/O是input/output的意思

IO一般可以分为两种:1.来自网络的IO 2.来自设备文件的IO

#### 1.同步IO：用户进程触发IO操作后就等待或者会轮询的去查看IO操作是否就绪。

特点：同步IO的执行者就是IO发起者， 同步IO需要发起者需要在用户态和内核态拷贝数据

#### 2.异步IO：用户进程触发IO操作后，不会去等待，而是去做其他事，当IO操作处理完后会得到一个IO处理完的通知

特点：完成时会得到IO的通知 异步IO的执行者是内核

#### 3.阻塞IO就是数据没来就一直等待

#### 4.非阻塞IO就是再等数据的时候去干其他事，提高效率。

#### 5.如何区分同步IO和异步IO？

当请求被阻塞就是同步IO，否则就是异步IO

#### 6.如何区分阻塞IO和非阻塞IO？

如果阻塞直到调用完成就是阻塞IO，否则就是非阻塞IO

7.异步就是异步：

IO模型只有4个概念：同步IO， 异步IO， 阻塞IO， 非阻塞IO， 有许多文章将这些两两结合，但在《uinx网络编程》根本没有提到过，

异步就是异步，只有同步才分阻塞和非阻塞，处理他们的缺点的方法就是多路IO复用。

同步阻塞，就是等待到IO操作返回，同步非阻塞就是一直轮询查看IO操作是否完成

异步就是发起IO操作后立即返回，cpu开始处理其他的事，当IO操作处理完后，在通过回调函数之类的通知cpu。（如果IO操作不是cpu去处理还可以让谁来处理呢？可以是DMA或者内存映射。）

### Reactor和Proactor区别

1. react用于同步IO， Preact用于异步IO

2. React模型：目前用的最多的，定义了3种角色： Reactor:负责监听和分配事件，将IO事件发送给对应Handler，事件包括读就绪，写就绪，新连接建立就绪

> Acceptor：处理与客户端建立新连接
>
> Handler：将Reactor发送来的事件与其绑定，然后进行非阻塞的读写任务后，处理完相关业务逻辑，再将结果写出返回

单Reactor单线程模型流程： Reactor通过select、epoll监控连接事件，收到事件会通过内部一个dispatch进行转发

如果是新连接，dispatch就会交给Acceptor创建连接，并且创建Handler去处理后续的读写事件

如果不是建立连接事件，dispatch就把事件交给对应的Handler处理

Handler会完成read->业务处理->send到客户端的流程。

> 单Reactor多线程模型： Reactor通过select、epoll监控连接事件，收到事件会通过内部一个dispacth进行转发

如果是新连接，dispatch就会交给Acceptor创建连接，并且创建Handler去处理后续的读写事件

如果不是建立连接事件，dispatch就把事件交给对应的Handler处理

Handler只负责响应事件，并读取事件，然后就交给Worker的线程池进行后续的业务处理

Woeker线程池会分配线程处理具体的业务逻辑，然后将结果返回Handler进行处理

Handler将Woeker线程池返回的结果通过send返回给客户端

主从Reactor多线程模型：Reacor分为两类：mainReactor：主要负责监听server socket，用来处理网络IO连接建立操作，并将建立好连接的socket分离出来交给subReacotr

SubRactor：主要负责由mianReacot分离出来的已经建立好连接的socket做数据交换和业务处理，subReactor个数应该与cpu个数相同

从线程池种随机选择一个线程作为mainReactor，用来绑定监听端口，与客户端建立连接

mainReactor通过Accept建立新socket连接，将其注册到其他的subReactor线程上，由其来负责三次握手，认证，ip黑白名单过滤

mianReacotr将建立的新连接的socket与自己分离，交给subReactor，subReactor并建立handler

Handler只负责响应事件，并读取事件，然后就交给Worker的线程池进行后续的业务处理

Woeker线程池会分配线程处理具体的业务逻辑，然后将结果返回Handler进行处理

Handler将Woeker线程池返回的结果通过send返回给客户端

3. Proactor模型：<img src="./images/media/image6.jpeg" style="width:6.66667in;height:3.03333in" />

> 模块关系： Proactor Initiator初始化Proactor，Handler，并将Proactor，Handler通过Asynchronous operation processor注册到内核
>
> Asynchronous operation processor负责处理注册请求，并完成IO操作，完成IO操作通知Proactor
>
> Proactor根据不同的IO触发对应的Handler进行业务处理，Handler也可注册新的Handler
>
> 流程： 应用程序初始化一个异步读取操作，然后注册相应的Proactor ，Handler，此时事件Proactor不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。
>
> Proactor等待读取操作完成事件
>
> 在Proactor等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。
>
> Proactor捕获到读取完成事件后，激活应用程序注册的Handler，Handler直接从缓存区读取数据，而不需要进行实际的读取操作。
>
> 异步IO来了->初始化Proactor，Handler->将Proactor，Handler注册到内核->Proactor等待IO事件处理完的通知->IO通知到了，Proactor通知handler去缓存区读取结果。

### 内存管理

1. 分区存储管理

   原理：把主存的用户区划分成若干个区域，每个区域分配个一个用户作业使用，并限定他们在自己的用户区运行

   划分方式： 固定分区：就是指定成不同固定大小的内存块

   动态分区：在作业加载的时候再给用户分配内存，一般内存大小就是作业的大小

   可重定位分区：这个是为了解决分区碎片化造成的空间浪费问题，就是把已经分配好的内存重新排列，排列成线性的连续区域

2. 分页存储管理

   原理：将一个进程的地址空间划分成若干个大小相等的区域，成为页，将内存空间划分成与页相同大小的物理快，成为块（32位每页大小4k）

3. 分段存储管理

   原理：将进程分为很多个段，分散再内存的不同区域，但是每个段都是一个连续的内存区域，系统为每个进程建立一张段映射表，每个段在表中有个开始地址和段长度，进程通过表可以访问到自己的全部内存区域。

4. 虚拟存储管理

   原理：引入虚拟存储器，程序在运行时访问的页如果已经在主存就继续运行，如果不在（缺页），程序发出缺页中断将需要的页加载到内存，如果内存已经满了，利用置换功能（就是页面置换算法）将暂时不用的内存调出到磁盘上

   页面置换算法： 最佳置换算法

   先进先出算法（FIFO）：队列

   最近最少使用算法（LRU）：栈

5. 内存优化的重要思路：保证应用程序的热点信息在内存中，经量减少换页和交换，多使用缓冲区。

### 进程crash常见原因:（常见段错误）

1. 访问受限制的内存区域： 往只读内存中进行写操作

   用户访问内核内存

2. 指针操作： 指针指向没有申请的内存区域

   释放一个已经释放了的指针

3. 内存耗尽： 堆栈溢出

   数组越界

4. 除0 文件描述符超过规定的限制

### Linux常用命名

cd mkdir touch ls find -name rm vim mv cp cat less more head tail ln ps -aux grep

chmod +x aaa.txt或者421（数字权限） unzip tar -xvf service mysql restart netstat -lt yum install yun list kill -n useradd -d /home/chaha -m chaha passwd chaha userdel chaha

groupadd chaha groupdel chaha top

### GDB调试

1. Gcc -g hello.c -o hello(要加-g)

2. gdb ./文件

3. b 行号; b func;

4. run next（直接往下运行） step(往下运行，会进入函数) finish(退出进入的函数) list（显示源代码）

5. p打印

6. display 变量名

7. 多线程：info threads thread ID

### 死锁如何解决，如何查找死锁位置

1. 死锁产生的4个条件： 互斥条件：进程分配到资源后，不允进程再占有资源

   请求保持条件：进程获得一部分资源又去请求另外的资源，但其他资源可能被占用

   资源不可剥夺条件：进程对已经获得的资源，再没有使用完之前，不会主动释放

   环路等待条件：存在进程-资源的环路

2. 解决办法： 资源一次性分配（破坏请求与保持条件）

   可剥夺资源（破坏资源不可剥夺条件）

   资源有序分配：给每个资源编号，让进程按编号递增方式去取资源，释放相反（破坏环路等待条件）

   1. 死锁位置： 每次获取锁就将当前的行号，线程id，以及能记录位置的信息，放入一个队列，释放的时候就出队列。如果有死锁，可以额外开个线程去查看，就是队列里面剩下的元素。

### 进程间通信

4. 普通管道pipe：血缘关系，父子，兄弟，半双工，一种特殊文件，但不属于文件系统，存在内存中。

5. 命名管道：无血缘关系，也是一种特殊的文件，存在文件系统中。

6. 消息队列：消息的链接表，存放在内核，有写权限的往消息队列添加消息，有读权限的进程取消息，消息队列具有特定的格式，和优先级，进程结束不会被删除，消息队列不一定要按先进先出读取，可以随机查询，可以根据事件的类型读取

7. 信号量：p操作，资源减1，v操作资源+1，资源=0，表示资源被用完。也可以加减整数。

8. 共享内存：通过系统api创建，要注意同步的处理。

9. 信号

10. 套接字

### Fork和vfork

1\. vfork是封装fork而来的。

2\. 使用fork创建的子进程，会复制父进程的所有地址空间，并发性更好。 Vfork创建的进程与父进程共享地址空间，子进程在地址空间做的修改对父进程也是可见的。（在exec，exit退出之前共享，之后就不共享了）

3\. fork创建的子进程调度顺序不确定，vfork保证子进程被exec或者exit才会开始调度主进程，如果调用这两个函数，需要主进程进一步操作，就会出现死锁

4\. fork采用写时复制，读时共享。

# 设计模式

## 常用设计模式介绍

### 创建型模式（Creational Patterns） 🎨

> **用于对象的创建，确保代码的灵活性和可扩展性**

| **设计模式** | **适用场景** | **关键点** | **示例** |
|:---|:---|:---|:---|
| **工厂方法（Factory Method）** | 创建对象的代码与使用对象的代码解耦 | 通过**子类**决定创建哪种对象 | **日志系统：**FileLogger **vs** DatabaseLogger |
| **抽象工厂（Abstract Factory）** | 需要创建**多个相关的对象**，但不希望指定具体类 | **一组工厂**共同创建产品 | **跨平台 UI：**WindowsButton **vs** MacButton |
| **单例（Singleton）** | 需要**全局唯一**的对象 | **私有构造+静态实例** | **数据库连接池、线程池** |
| **建造者（Builder）** | 需要**分步骤**创建复杂对象 | 分离**构造过程和表示** | **生成 HTML、PDF 文档** |
| **原型（Prototype）** | 需要**克隆**已有对象，而不是重新创建 | **深拷贝 vs 浅拷贝** | **游戏角色克隆、对象缓存** |

### 结构型模式（Structural Patterns） 🏗️

> **处理类和对象之间的组合，帮助构建更灵活的系统结构**

| **设计模式** | **适用场景** | **关键点** | **示例** |
|:---|:---|:---|:---|
| **适配器（Adapter）** | 旧代码或第三方库**接口不兼容** | **转换接口**，类适配 vs 对象适配 | **电源适配器（220V → 5V）** |
| **桥接（Bridge）** | 需要**解耦多个维度的变化** | 抽象部分和实现部分**独立扩展** | **绘图 API：形状** Shape **vs 设备** Renderer |
| **装饰器（Decorator）** | **动态**添加功能，而不修改原始类 | **比继承更灵活** | **咖啡店：基本** Espresso **+** Milk **/** Sugar |
| **外观（Facade）** | 提供**简化的访问接口** | **封装复杂子系统** | **Spring** TransactionManager |
| **享元（Flyweight）** | **优化大量相似对象的内存使用** | **共享对象，避免重复创建** | **字体渲染，线程池** |
| **组合（Composite）** | **树形结构**，需要统一操作 | **叶子对象和组合对象一致** | **文件系统（文件 vs 文件夹）** |
| **代理（Proxy）** | **控制对象的访问** | **远程代理、安全代理、虚拟代理** | **远程方法调用（RMI）** |

### 行为型模式（Behavioral Patterns） 🎭

> **关注对象如何交互和职责分配，提高代码的灵活性和可维护性**

| **设计模式** | **适用场景** | **关键点** | **示例** |
|:---|:---|:---|:---|
| **策略（Strategy）** | 需要**动态切换算法** | **避免 if-else 逻辑** | **支付方式：支付宝 vs 微信** |
| **观察者（Observer）** | **一对多依赖**，对象变化时通知订阅者 | **发布-订阅模式** | **事件监听，消息推送** |
| **责任链（Chain of Responsibility）** | **多个对象**按顺序处理请求 | **解耦请求的发送者和处理者** | **日志处理系统（File → Console）** |
| **命令（Command）** | 需要**封装请求**，支持撤销 | **命令对象封装请求** | **遥控器（Undo/Redo 功能）** |
| **备忘录（Memento）** | 需要**保存对象状态，支持撤销** | **快照机制** | **文本编辑器** Ctrl+Z |
| **状态（State）** | 对象在**不同状态**下有不同行为 | **避免大量 if-else** | **TCP 连接状态（CLOSED/LISTENING）** |
| **模板方法（Template Method）** | **定义算法骨架**，子类实现具体步骤 | **代码复用，控制流程** | **游戏 AI 行为模式** |
| **迭代器（Iterator）** | 需要提供**统一方式遍历集合** | **封装集合的遍历逻辑** | **STL 容器** std::vector<int>::iterator |
| **中介者（Mediator）** | **封装对象间复杂交互** | **避免对象之间的直接依赖** | **GUI 组件交互** |
| **访问者（Visitor）** | **不同操作作用于对象结构** | **分离数据结构和操作** | **XML 解析器** |

### 单例模式

1. 一个类只有一个实例，并提供一个全局访问点来访问这个实例(getInstace())

2. 这个类只有一个实例(静态函数static）， 它必须自己创建实例（构造在类里面，并且设置为私有，通过getInstace调用） 它必须像整个系统提供这个实例（直接声明类去调用getInstace）

3. 单例模式不提供线程安全，可以通过互斥锁，在getInstace调用构造时加锁。

### 如何设计内存池

内存池基本概念

- 内存池是一种预分配内存机制，提前申请一大块内存，然后将其划分多个小块内存，用户根据需要从内存池中获取内存，当内存不再需要时，内存返回内存池，不释放给操作系统，这样可以避免频繁的内存分配和回收操作，减少系统开销和内存碎片化

设计原则

- 固定大小的内存快：内存池应当将内存分为固定大小的块，每个内存块大小相同，确保内存分配和回收的简单性
- 避免内存碎片化：使用链表或位图等方式跟踪空闲内存块，可以避免内存池内存使用的碎片化问题
- 快速分配与回收：内存池应该能够在常数时间内完成内存分配和回收操作。这通常通过维护一个空闲内存块的列表来实现，分配时直接从列表中取出一个空闲块，回收时将块放回列表
- 线程安全：对于多线程环境，内存池需要保证线程安全。通常会使用锁机制来保护内存池的数据结构，避免并发访问时的竞态条件

内存池实现步骤

- 初始化内存池：在创建内存池时，预先分配一块大内存，并将其划分为多个固定大小的内存块。这些内存块的地址被添加到空闲链表中，表示它们是空闲的，可以被分配
- 分配内存块：当用户需要分配内存时，内存池从空闲链表中取出一个空闲的内存块，并将其从链表中移除。如果空闲链表为空，则扩展内存池，分配更多的内存块
- 回收内存块：当用户释放内存时，内存池将内存块返回到空闲链表中，表示它可以被再次分配
- 销毁内存池：在应用程序结束时，销毁内存池，释放所有预先分配的内存

代码示例：

```c++
#include <iostream>
#include <vector>
#include <mutex>
#include <memory>

// 内存池类模板
template <typename T, size_t BlockSize = 1024>
class MemoryPool {
private:
    // 内存块结构，用于链表管理空闲内存块
    struct FreeNode {
        FreeNode* next;
    };

    // 每块内存中包含的对象数量
    size_t m_blockSize;
    // 所有分配的内存块
    std::vector<void*> m_blocks;
    // 空闲内存块链表的头指针
    FreeNode* m_freeList;
    // 线程安全锁
    std::mutex m_mutex;

public:
    // 构造函数，初始化内存池
    explicit MemoryPool(size_t blockSize = BlockSize)
        : m_blockSize(blockSize), m_freeList(nullptr) {
        allocateBlock(); // 初始分配一个内存块
    }

    // 析构函数，释放所有分配的内存块
    ~MemoryPool() {
        for (auto block : m_blocks) {
            ::operator delete(block); // 释放每个内存块
        }
    }

    // 分配内存，返回指向 T 类型的智能指针
    std::shared_ptr<T> allocate() {
        std::lock_guard<std::mutex> lock(m_mutex); // 线程安全
        if (!m_freeList) {
            allocateBlock(); // 如果空闲链表为空，分配新的内存块
        }
        // 从空闲链表中取出一个节点
        FreeNode* node = m_freeList;
        m_freeList = node->next;
        T* ptr = reinterpret_cast<T*>(node);
        //引用计数为0自动调用deallocate
        return std::shared_ptr<T>(ptr, [this](T* p) { deallocate(p); });
    }

private:
    // 释放内存，将指针返回到内存池
    void deallocate(T* ptr) {
        std::lock_guard<std::mutex> lock(m_mutex); // 线程安全
        // 将释放的内存块重新加入到空闲链表
        FreeNode* node = reinterpret_cast<FreeNode*>(ptr);
        node->next = m_freeList;
        m_freeList = node;
    }

    // 分配一块新的内存区域，并将其划分为多个 FreeNode，加入到空闲链表中
    void allocateBlock() {
        // 计算每个内存块的大小，确保对齐
        size_t size = sizeof(FreeNode) > sizeof(T) ? sizeof(FreeNode) : sizeof(T);
        // 分配一大块内存
        char* block = static_cast<char*>(::operator new(size * m_blockSize));
        m_blocks.push_back(block); // 记录分配的内存块
        // 将新分配的内存块划分为多个 FreeNode，并加入空闲链表
        for (size_t i = 0; i < m_blockSize; ++i) {
            FreeNode* node = reinterpret_cast<FreeNode*>(block + i * size);
            node->next = m_freeList; // 将当前的node的next指向当前的空闲链表的表头
            m_freeList = node;       // 将当前的node设置为新的空闲链表表头
        }
    }
};

// 示例类，用于测试 MemoryPool
class MyObject {
public:
    MyObject(int data = 0) : data_(data) {
        std::cout << "MyObject constructed with data = " << data_ << std::endl;
    }
    ~MyObject() {
        std::cout << "MyObject destructed with data = " << data_ << std::endl;
    }
    int data_;
};

int main() {
    MemoryPool<MyObject> pool; // 创建内存池

    auto obj1 = pool.allocate(); // 从内存池中分配对象
    new (obj1.get()) MyObject(10); // 使用 placement new 构造对象

    auto obj2 = pool.allocate();
    new (obj2.get()) MyObject(20);

    // 不需要手动调用析构函数和释放内存，智能指针会自动管理

    return 0;
}


//总结，内存池设计需要用到的数据结构（简易）  一个vector记录所有的内存块，定义一个空闲内存块结构体，一个空闲内存链表用于保存空闲内存，最好对使用的内存块使用智能指针，引用计数为0，即内存块没人使用了，自动加入到空闲内存链表。
//构造时就可以先初始化一个内存块，记录在vector中，然后均分内存块为固定大小，记录在空闲内存链表
//使用时从空闲链表中取一个节点即可，如果空闲内存链表用完了，就在开辟一块内存块并记录在vector，和均分内存块记录在空闲内存链表中
//用户申请的内存使用完后，重新添加到空闲内存链表
//最后程序结束释放内存，归还给操作系统
```

#### 如何设计内存池的动态缩容和扩容

内存池的缩容扩容本质是**空间换时间**与**碎片控制**的平衡：通过预分配、链表管理和智能回收策略，减少系统调用开销，同时动态适应负载变化。实际实现需结合场景选择固定/可变块策略，并嵌入安全与性能监控机制

- #### 动态扩容操作：

  这个在上面就已经提到一点，维护一个空闲内存链表m_freeList，当空闲内存用完了，从操作系统再调用new获取一块内存并记录在vector<void*> m_blocks，然后拆分为一组固定大小内存块，继续往m_freeList里面添加内存组。下面补充一些策略

  - **空闲链表管理**

    维护空闲块链表，分配时从链表头部取用。当链表耗尽时触发扩容：计算所需新块数量，调用系统接口申请内存，分割为固定大小块并加入链表

  - **合并与分割**

    可变大小的内存池将大块内存按需分割为更小单元，或合并相邻空闲块以应对不同需求，提高利用率。

- #### 动态缩容操作：

  - **负责感知回收**

    监控系统负载，低负载时触发缩容：释放未使用的预分配块或空闲链表中的多余块，即有个监控线程监控着内存池

  - **安全擦除与归零**

    释放前对敏感数据内存进行清零或随机化处理，防止信息泄漏（适用于安全敏感场景）

- #### 动态调整的一些策略

  - **分层管理**

    **固定与可变块结合**：将内存池分为多层，底层管理固定大小块（如4KB），上层处理可变需求。例如，Web服务器可为不同请求类型分配专用子池，按需扩展子池容量

  - **线程安全与锁优化**

    - **细粒度锁**

      多线程环境下，为每个空闲链表或子池分配独立锁（如`std::mutex`），减少竞争

    - **无锁设计**

      使用原子操作或线程本地存储（TLS）（即线程本地变量thread_local）实现无锁分配，适用于高频小对象场景

  - #### **碎片控制**

    - **块对齐与预分类**

      内存分配按8/16字节对齐，减少访问延迟。预分配不同大小的块链表（如64B、128B），按需求分类分配

    - **定期整理**

      后台线程定期合并碎片化空闲块，或迁移数据到连续内存区域





## 如何设计线程池

- 线程池的核心组件

  - 任务队列：用于存储需要执行的任务
  - 工作者线程：真正执行任务的线程。从任务队列中获取任务并执行
  - 线程池管理器：复杂线程的创建、调度和销毁，以及监控线程池的状态

- 线程池的工作流程

  - 任务提交：任务被提交到线程池时，首先会加入到任务队列中
  - 线程获取任务：空闲的工作线程会通过一些方式从任务队列中取任务
  - 任务执行：工作线程执行完后，会将结果返回给调用者，并回到空闲状态
  - 线程回收：如果任务队列中没有更多的任务需要处理，并且当前的线程数量超过了最小值，则多余的线程会被回收，以节省资源。

- 线程池的状态管理

  - **RUNNING**：正常状态，接受新任务并处理队列中的任务。
  - **SHUTDOWN**：不接受新任务，但会继续处理队列中的任务。
  - **STOP**：不接受新任务，不再处理队列中的任务，并中断正在执行任务的线程。
  - **TIDYING**：所有任务都已销毁，线程池即将终止。
  - **TERMINATED**：线程池完全终止。

- 当任务队列已满且线程池中的线程数达到最大值时，线程池会执行**拒绝策略**，这个灵活选择策略方法

  ```c++
  #include <iostream>
  #include <vector>
  #include <queue>
  #include <thread>
  #include <mutex>
  #include <condition_variable>
  #include <functional>
  #include <future>
  #include <atomic>
  #include <chrono>
  
  class ThreadPool {
  public:
      // 初始化线程池时，设置最小线程数 minThreads 和最大线程数 maxThreads，并创建初始的工作线程。
      explicit ThreadPool(size_t numThreads) : stop(false), minThreads(numThreads), maxThreads(numThreads * 2) {
          for (size_t i = 0; i < numThreads; ++i) {
              addWorker();
          }
      }
  
      // 析构函数，安全关闭线程池
      ~ThreadPool() {
          {
              std::unique_lock<std::mutex> lock(queue_mutex);
              stop = true;
          }
          condition.notify_all();
          for (std::thread &worker : workers) {
              worker.join();
          }
      }
  
      // 提交任务到线程池
      template<class F, class... Args>
      auto enqueue(F&& f, Args&&... args) -> std::future<typename std::result_of<F(Args...)>::type> {
          using return_type = typename std::result_of<F(Args...)>::type;
          auto task = std::make_shared<std::packaged_task<return_type()>>(
              std::bind(std::forward<F>(f), std::forward<Args>(args)...)
          );
          std::future<return_type> res = task->get_future();
          {
              std::unique_lock<std::mutex> lock(queue_mutex);
              if (stop) throw std::runtime_error("enqueue on stopped ThreadPool");
              tasks.emplace([task]() { (*task)(); });
          }
          condition.notify_one();
          adjustThreadPoolSize();
          return res;
      }
  
  private:
      std::vector<std::thread> workers; // 工作线程组
      std::queue<std::function<void()>> tasks; // 任务队列
      std::mutex queue_mutex; // 互斥锁，保护任务队列
      std::condition_variable condition; // 条件变量，用于任务通知
      std::atomic<bool> stop; // 停止标志
      size_t minThreads; // 最小线程数
      size_t maxThreads; // 最大线程数
  
      // 添加一个工作线程
      void addWorker() {
          workers.emplace_back([this] {
              while (true) {
                  std::function<void()> task;
                  {
                      std::unique_lock<std::mutex> lock(queue_mutex);
                      condition.wait(lock, [this] { return stop || !tasks.empty(); });
                      if (stop && tasks.empty()) return;
                      task = std::move(tasks.front());
                      tasks.pop();
                  }
                  task();
              }
          });
      }
  
      // 根据任务队列的状态调整线程池的大小。如果任务队列中的任务数量超过了当前的工作线程数，并且工作线程数小于最大线程数，则添加新的工作线程。如果任务队列为空，并且工作线程数大于最小线程数，则停止一个工作线程。
      void adjustThreadPoolSize() {
          std::unique_lock<std::mutex> lock(queue_mutex);
          if (tasks.size() > workers.size() && workers.size() < maxThreads) {
              addWorker();
          } else if (tasks.empty() && workers.size() > minThreads) {
              stopWorker();
          }
      }
  
      // 停止一个工作线程
      void stopWorker() {
          {
              std::unique_lock<std::mutex> lock(queue_mutex);
              stop = true;
          }
          condition.notify_one();
          workers.back().join();
          workers.pop_back();
          stop = false;
      }
  };
  
  // 示例用法
  int main() {
      ThreadPool pool(4); // 创建包含4个线程的线程池
  
      // 提交任务到线程池
      for (int i = 0; i < 8; ++i) {
          pool.enqueue([i] {
              std::cout << "Task " << i << " is running in thread " << std::this_thread::get_id() << std::endl;
              std::this_thread::sleep_for(std::chrono::seconds(1));
          });
      }
  
      std::this_thread::sleep_for(std::chrono::seconds(10)); // 等待所有任务完成
  
      return 0;
  }
  
  //总结，线程池需要的数据结构（简单） 一个vector<std::thread>工作线程组，一个queue<std::function<void()>>任务队列，以及condition_variable条件变量，负责通知工作线程执行
  //先创建一组线程，里面会有个while(1),等待任务队列有任务的时候来通知condition.wait
  //然后往任务队列添加任务，并通知工作线程condition.notify_one()
  //优雅停止condition.notify_all()通知所有线程完成自己的任务然后退出
  //这里没有调度器，可根据情况补充
  ```


#### 如何设计线程池的动态扩容和缩容

##### 动态扩容与缩容的触发条件

1. **扩容触发条件**
   - 任务队列满载：当任务队列长度超过阈值时，说明现有线程无法及时处理任务，需增加线程
   - 线程利用率高：若核心线程全部忙碌且CPU负载较高，需扩容至最大线程数以提升吞吐量
   - 预测性扩容：基于历史负载预测未来峰值，提前增加线程（如电商大促场景）
2. **缩容触发条件**
   - 线程空闲超时：设置线程存活时间（如`keepAliveTime`），空闲线程超时后自动回收
   - 任务队列持续为空：队列长时间无任务且CPU利用率低，逐步减少活跃线程
   - 系统资源紧张：通过监控内存或CPU使用率，主动释放线程以缓解资源压力

##### 实现扩容的动态核心机制

- #### C/C++线程池一些机制
  - 线程数量管理：
    - 维护最小/最大线程数，通过条件变量（`condition_variable`）和互斥锁（`mutex`）同步线程状态
    - 缩容时向空闲线程发送“退出信号”，等待其完成任务后销毁
  - 任务分发优化：
    - 使用工作窃取（Work Stealing：它的基本思想是：每个线程都有一个双端队列（deque）来存储任务，当一个线程完成了自己的任务队列中的所有任务时，它会从其他线程的任务队列中“偷取”任务来执行，从而避免线程闲置，提高资源利用率）算法平衡线程负载，减少任务堆积

- ##### 动态配置与监控
  - 参数动态化（配置时候变更）：
    - 通过配置中心（如ZooKeeper或Nacos）实时更新线程池参数，无需重启服务
    - 结合YAML或数据库存储线程池配置，支持多环境灵活调整
  - 监控与告警：
    - 采集线程池指标（活跃线程数、队列长度、拒绝任务数），设置阈值触发告警

##### 动态扩容算法策略

1. 基于队列长度的线性调整：
   - 当队列长度超过阈值时，按固定步长增加线程（如每次扩容2线程）。
2. 自适应反馈控制：
   - 根据CPU利用率和任务处理延迟动态计算目标线程数（公式：线程数 = CPU核心数 × (1 + 等待时间/计算时间)）。
3. 指数平滑预测：
   - 使用滑动窗口统计历史负载趋势，预测未来任务量并提前扩容。
4. 混合策略：
   - 高峰期采用激进扩容（如指数增长），低峰期缓慢缩容（如线性减少），平衡响应速度与稳定性。

# 项目遇到的问题和项目总结

## 问题:

1.协程调度器时，idel协程，如果当调度器没有任务时，调度协程就会陷入idel协程中去，等待新任务加入就退出idel协程，但阻塞在idel协程上，整个线程就阻塞了，这个线程就不能创建新任务，就类似于先有鸡还是先有蛋的问题：

只有创建新任务才能退出idel协程，只有idel协程退出才能创建新任务。

处理：简单粗暴，直接轮询，如果消息队列为空，就一直轮询，所以tictle函数就没有实现，因为不需要它去通知，还有设置autostop标志，这个标志会让调度协程完成调度任务后自动退出

2.协程调度器中，因为协程设计的是非对称模型的，只能在主协程和子协程来回切换，当user_call为true时，线程数量为1时，一个线程除了创建调度的协程，还调度协程，任务协程，3个协程的切换了，

解决办法：设置3线程变量， 分别存储3个协程的id。同时设置一个bool变量m_isscheduler，如果这个变量为真，表示需要被调度协程调度，可以用于调度协程和子协程切换，如果为假，表示不需要经过调度协程调度，可以用于创建调度的协程和调度协程之间的切换。

协程调度器中，关于使用了user_caller参数，并且只有main线程，按照普通流程，先往任务队列里面添加任务，然后再启动调度协程开始调度这些任务，也就是进入run函数，后面的代码暂时不执行，去执行run函数，因为run函数里面是个死循环，如果idel协程的状态不能被设置为TERM（结束状态），就会一直死循环，但是要让idel协程被设置成为TERM状态，必须要执行stop函数，所以程序就会被一直卡再run函数里面，不能停止了

> 解决办法：把call为true的调度器放到stop中去执行resume()，这样，m_stopping已经被设置为true，只要任务做完，调度器也就会停止。

## 项目总结：

### **协程调度**：

1. 整体思路：协程调度器里面维护一个任务队列（实际是用链表实现的）和线程池。开始调度后，线程池从任务队列里按顺序取出任务执行。调度线程可以包含caller线程（主线程）。当全部任务都执行完了，线程池停止调度，等新的任务进来。添加新的任务后，通知线程池有新的任务进来了，线程池重新开始运行调度，停止调度时，各调度线程退出，调度器停止工作。

2. 具体：

   1.调度器：调度器再初始化时，可以指定一个参数user_caller，表示是否用当前线程的主协程创建调度器和线程数threads，如果user_caller为true，线程数自动减1，同时初始化一个调度协程m_rootFiber（属于main线程的调度协程），保存起来，这是因为在stop函数中要判断是否使用了call参数，当只有一个main线程时，start不会创建线程池，不会做任何操作。

    2.任务队列：是一个一个链表std::list<ScheduleTask> m_task ScheduleTask是在Scheduler类里面定义的一个结构体，用来存储任务，包括3个成员变量，Fiber::ptr fiber, function<void()> cb, int thread;定义了多个构造方法，传函数，也可以传一个协程指针，可以指定调度的线程号，也可以让thread = -1，表示任意调度线程。 再加个初始化函数，给成员变量默认值，分别为nullptr nullptr -1;

3. 线程池：定义:std::vector<Thread::ptr> m_threads;跟线程池配套的还有个工作线程数size_t m_threadCount = 0，这个主要是计数的，但不算caller线程。线程池是再void start()中被赋值的，每个线程初始化都被绑定到一个run()函数。这些线程都是调度线程，调度线程一旦创建，就会立刻从任务队列里取任务执行。因为创建线程pthread_create是会直接进入创建好的线程中去执行的，就像fork()函数。

4. Start()函数，主要就是负责初始化线程池并启动，将每个调度线程都绑定个run方法。

5. Stop（）方法，主要停止协程调度器，规定，当停止时，调度器如果还有任务没处理完，应该先等它把所有任务处理完，在返回到main线程，再结束，结束的前提就是要让所有的任务都执行完了，再退出。如果时call线程，并且只有一个main线程时，会在stop()函数里去执行它的调度。Stop（）函数里面有个参数m_stopping，进入后stop（）后m_stopping被设置为true，这样run（）函数也才会停止。

6. Run（）函数，调度线程会一直从任务队列里面取任务，这里设计的是个死循环，如果有的任务是指定了调度线程，就标志下，不处理，交给后面的线程处理，然后开始处理任务，函数就执行它的函数，协程就执行它的协程，如果没有任务了，就会进入idel协程，idel协程里面会直接退出，什么都不做，然后再进入循环，等任务。为了解决run（）函数能自动停止，加入一个stopping()函数，判断调度是否可以停止了，当任务队列为空，活跃线程为0，触发了stop（）函数时，idel进入resume（），被设置为TERM，下次再进入循环，run()就会被退出。

7. static thread_local Scheduler *t_scheduler = nullptr;这个是调度器的实例，一般创建几个就几个，调度器一般会对应多个调度线程， static thread_local Fiber *t_scheduler_fiber = nullptr;这个是保存当前线程调度协程，如果caller不为true，除了main线程，都应该有个调度协程变量

8. 添加任务，定义了一个模板函数，通过void schedule()函数，初始化ScheduleTask任务结构体，并将任务放入任务队列，然后再加一个通知tickle（）函数。
9. 整体框架
   
   1. 线程数为1，且use_caller为false，对应额外创建一个线程进行协程调度、main函数线程不参与调度的情况。

![image-20250225145249689](F:\工作\面试问题总结\study\面试准总结\images\media\image-20250225145249689.png)

​					main函数占一个线程，执行main中相关的操作，调度的时候使用其他的线程去调度，有单独的调度线程，再在调度线程里面去执行协程的切换即执行run函数

​		2.线程数为1，且use_caller为true，对应只使用main函数线程进行协程调度的情况。

​		![image-20250225145408996](F:\工作\面试问题总结\study\面试准总结\images\media\image-20250225145408996.png)

​		这个因为调度线程和mian函数在同一个线程，main要执行，调度也要执行，肯定是不能不同时进行的，因此就有顺序，因此这种模式的在start函数中就不在绑定run函数，实际这里是通过创建调度器的时候就指定了，不创建多余的线程，这样线程池其实也就是没有创建线程，因此start没有对于这种模式就是什么都不做。

​		然后还是先在main中添加任务，在最后，调度要停止的时候，在切换到调度器的上下文执行，这时候再把所有的任务一次性执行完，并且退出调度。就是相当于把所有的任务，延迟到调度器的stop中去执行。

在main函数线程里这三类协程运行的顺序是这样的：

1. main函数主协程运行，创建调度器

2. 仍然是main函数主协程运行，向调度器添加一些调度任务

3. 开始协程调度，main函数主协程让出执行权，切换到调度协程，调度协程从任务队列里按顺序执行所有的任务

4. 每次执行一个任务，调度协程都要让出执行权，再切到该任务的协程里去执行，任务执行结束后，还要再切回调度协程，继续下一个任务的调度

5. 所有任务都执行完后，调度协程还要让出执行权并切回main函数主协程，以保证程序能顺利结束。

### IO协程调度器

使用IO事件调度可以将开发者从判断socket fd是否可读或可写的工作中解放出来，使得程序员只需要关心socket fd的IO操作，用点像异步IO的思想

1. 整体思路：IO协程调度器是继承于协程调度器上的，基于epoll实现的，对每个fd，都认为有两个事件一个是可读事件(EPOLLIN)，一个是可写事件(EPOLLOUT)，枚举的事件也是来源于epoll的，就无事件，读事件，写事件，没有加工，但是虽然只枚举了读写事件，但是可以将其进行归类，将其他的什么EPOLLERR，EPOLLHUP，都通过可读可写事件来表示，甚至可读可写事件。

2. 然后就是关于fd的一些封装，定义了一个私有结构体FdContext，里面定义了描述符，事件类型（可读可写），回调函数（协程），描述符和事件类型用于epoll_wait，回调用于协程调度，这些信息可以通过epoll_event.data.ptr这个指针来指向。每添加一个FdContext，就把它加入一个socket上下文容器中取，一个vecotr<FdContext*> m_fdContexts的数组。因为fd是会呗重复利用得，所以不会增长太快。

3. Idel协程处理，再协程调度器中idel协程中什么都没干，在IO协程调度器中，idel用来处理fd事件，实际上idel并不负责处理fd的回调函数这些，回调是在下次进入run()函数处理的，idel主要是负责收集fd事件，有读写事件，通过triggerEvent（event），就把它加入到scheduler中的任务队列中去，然后再下去进入run（）中的循环来处理。因为每个fd都有可读事件，可写事件，所以要idel再收集完后，要判断下，是否还有事件没处理完，没处理完就要重新添加到epoll_wait上去，处理完就可以从epoll_wait上删除了。然后yield退出到调度线程上去处理。

4. IO协程调度支持删除事件（直接删除），取消事件（提前执行），方法都是一样得，都是先遍历m_fdContexts[fd]找到它的FdContext结构体，如果是删除就直接将这个事件的读或写事件删除，如果是取消就是提前将这个事件触发，然后它们也都会再看这个fd还有没有事件，有酒重新epoll_ctl，添加回红黑树上面，没有就删除fd。添加事件，是先看fd存不存在，不存在，重新分配一个，然后添加事件，但一个fd不允许添加两个相同的事件，将新添加的事件放入epoll_wait，再event.data.ptr = Fdcontext，然后给Fdcontext添加回调函数或者回调协程.

5. 整个IO调度器的IO都是非阻塞的，采用的ET模式，每个消息只会通知一遍，所以要尽快处理，IO协程调度的tickle()被重写，epoll_wait返回的条件有两个，一个是有事件发生，第二个就是tickle（）调用，往管道里面写个数据，触发epoll_wait。

6. 关于IO协程调度的停止，再协程调度的基础上，stopping()基础上再加个m_pendingEventCount,每次添加事件，删除事件都会维护m_pendingEventCount这个变量，当m_pendingEventCount为0stopping()为true，退出idel。

### 日志模块

1. 日志部件：LogFormatter:日志格式器，构造是传一个pattern作为默认格式，然后类里面还有个FormaItem，该类有个虚函数format，再后续会派生出很多子类，专门负责把某个字符输入到流中，一般流程为，输入构造传入pattern格式字符串，然后开始init（）解析，解析函数里面会有个map结构，key是格式字符，value这个key对应的格式字符类的智能指针，加入那些键值对，是要根据变量pattern才知道的，最后把这些value放入一个vector<FormatItem::ptr> m_items的数组，然后调用LogFormatter的format，遍历m_items数组，将对应类的format的输出，输入到流中，然后返回流，这样就把日志格式化到流里面了，设计思路就是LogFormatter有个format里面再写个类也是虚函数的format, LogFormatter的format是把调用所有的子类format，总的输出，但再内部调用时，调用foramt是具体到每个子类中去的，很巧妙。

2. LogAppender:日志输出器，有两个子类，一个是指定输出到终端，一个是指定输出到文件的，成员变量里面存储着有个LogFormatter类的智能指针，和一个log（）输出方法。其实这个log（）方法，主要还是转调LogFormatter的formatter的方法，输入到流里面，再返回。

3. Logger:日志器负责进行日志的输出，日志器有多个LogAppender，成员变量有个list<LogFormatter::ptr> m_appenders;可以通过Logger的Log（）将链表中的数据进行一次性输出，也就是说一个Logger可以有多个LogAppender；每个Logger有个自己的日志级别，只有要输出的日志级别>=日志器的日志级别，才会被允许输出。

4. LogEvent:日志事件，这个是存储日志的信息的类，再使用日志时，这个类要先初始化。文件名和行号是通过宏获取的__FILE__ __LINE__

5. LogEventWrap:日志事件包装类，就是将日志事件，和日志器封装在一起，一般一个日志事件对应一个日志器，封装在一起方便后面宏定义调用。通过，构造初始化，析构时调用Logger的log（）方法，可以一次性调用。

6. LogManger:日志器管理类，单例模式，用于管理所有的日志器，类成员中有个map<std::string, Logger::ptr> m_loggers，可以对所有的日志器进行管理。获取某个日志器时，有就返回，没有创建再返回。

### 配置模块

整体：约定优于配置，也就是说配置参数都有个默认值。对大小写不敏感（因为会被全部转成小写）

1. ConfigVarBase:配置项的基类，成员只有配置项的名称，配置参数的描述。有两个toString/fromString的虚函数，具体的由子类实现。

2. ConfigVar:具体的配置项类，这是一个模板类，第一个模板参数是类型，表示配置项的类型，另外两个是FromStr ToStr，为仿函数，是把boost中的类型转化:lexical_cast<T>(v),将T类型转化为其他类型(F)，FromStr是将string转换为类型T，ToStr是将T类型，转化为string，但lexical_cast<T>(v)只支持常用数据类型，不支持stl容器，因此对lexical_cast实现了关于stl的偏特化，可以让lexical_cast支持对容器类型和string之间的转化。

   这个类还提供了回调函数，如果setValue（）更新了一个配置，就会触发所有配置的回调函数，类成员中有个map结构map<uint64_t, on_change_cb> m_cbs，on_change_cb是个函数模板，参数为配置项的旧值，配置项的新值，如果配置发生更新，会触发所有的回调函数，主要用来通知的。有addListener/delListener可以用来增添删除回调函数。

3. Config:ConfigVar的管理类，类里面所有的成员函数，变量都是静态的，保证全局只有一个。提供Lookup（），用于根据配置名查看配置项，如果查询时提供默认值，对已经存在的就会更新，不存在的会创建，LoadFromYaml用于加载Yaml配置文件，将Yaml配置加载到配置项中，并更新。

## 科来项目总结

### 公共配置

- 背景：上层管理系统（upm）下发的配置中存在大量每条链路完全一样的配置 ，当链路数目过多，在连接配置加载和更新，以及连接upm时，时间过久，并且有很多额外内存开销。
- 方案：主要优化配置是网段和应用，将配置分为公共配置和私有配置，新增公共网段和应用的配置文件，将之前的配置文件设定为私有配置，保证加载顺序私有配置>公共配置>系统配置，并且与upm协商一致的下发策略（回溯服务器如何下发配置是否为公私有和增删改查的xml格式）和根据场景优化配置加载机制（如在连接upm保证配置一致会先删除配置，但回溯还是会将配置加载流程走完，导致协议识别引擎反复加载，浪费很多性能，跟据场景做优化，让其提前退出），并且包括兼容问题（比如网段配置的带宽放开校验导致带宽超过100%，以及upm的断开配置策略）。
- 在一个是回溯的客户端的修改，客户端主要是获取配置，原来是存在两种加载情况，异步通知，和直接加载，什么时候走那种加载流程，是由场景决定的，异步一般是用于upm的配置，因为一般upm配置量会很大，在获取配置的handle，即配置类型分别解析，并展现，并且需要兼容。
- 回溯的配置是存在多缓存机制的，当有web，控制台有配置变更操作，会通过ipc告知配置进程，配置进程会生成一个多缓存对象，这个多缓存是可以再进程间访问的，配置进程会将配置落盘，在通知对应的进程加载配置，这样达到配置同步。其他比如分析进程在使用时，也可直接从多缓存读配置并加载。但这里，不能新增一个新的配置类型，这样修改量会更大，配置解析流程还是公用同一个，因此在原来存放应用和网段的多缓存中新增一个指向公共配置多缓存的指针，在通过配置的标签，将配置落盘到不同的文件中，这样就可以保证每个链路都可以从同一个多缓存中取到所有的公共配置了

### Kerberos认证

- 描述**：**满足企业级安全合规要求，实现Kafka集群的Kerberos认证
- 实现：认证配置由upm下发，两个认证文件，和一个密码，新增一个文件传输协议，按字节序读取，然后本地组装，在由配置更新加载落盘，但原有的xml格式kafka并不兼容，因此在本地自己新增一套解析逻辑，将xml配置转换为yml格式并落盘，在通知query进程，让qeury进程去读取这个yml格式的文件，加载kafka生产者的配置。
- 因为kafka数据推送是要先查数据，为了减少拷贝，框架上设计的是将kafka的推送功能放在query进程里，查询是定义了几个不同的类，表示来自不同对象的查询，upm，客户端，kafka推送，kafka推送也是分了类一个json格式，一个二进制格式，在通过本地组装头部和body，经由rdkafka的三方接口将数据发送出去。

### 数据内存化

- 背景问题： 回溯服务器支持数据包回放，但存储预分配策略不合理，导致在存储利用率极高的情况下系统压力大，而空闲时内存资源未能充分利用，同时存在内存泄漏隐患。 
- 解决方案： 前端链路存储配置新增内存类型，并且显示当前内存使用情况，兼容之前的存储配置，因为回溯的数据存储是关系数据库，数据都是按表存，当在往一张表写数据时，如果一次性数据过大，超过了每张表的缓存大小，是会临时开辟新的内存，因此通过注册表形式，限制用户将内存全部用于配置存储。
- 回溯的数据是分为时间桶的，分为s桶，min桶，h桶，d桶，桶之下才有各种统计表，每个表又有自己的缓存，但之前的内存分配逻辑是写死的，因为以前只是作为一个写的缓存区，这里需要制定策略，通过讨论，比如tcp会话，ip会话这种数据量大的分配的内存比例就多，而像概要表这种的，分配比例就小，最后为每一个表都制定一个比例，然后再数据落盘时，区分配置类型，使数据不落磁盘。查询时，直接保证数据优先查询内存，磁盘空就不查。

### 回溯部分框架

分析的大致流程：

![img](F:\工作\面试问题总结\study\面试准总结\images\media\wps1.jpg)

配置的框架：

​					![多进程配置流程](F:\工作\面试问题总结\study\面试准总结\images\media\多进程配置流程.png)

## 常用组件

### git工作流程

![img](F:\工作\面试问题总结\study\面试准总结\images\media\84a7a87c9b738213fb4aaf1604d8f889.png)

#### 1.工作区

用户直接编辑文件的目录，所有修改在此进行

#### 2.暂存区

临时存储待提交的修改（通过 `git add` 添加）

#### 3.本地仓库

保存提交历史的数据库（通过 `git commit` 提交）

#### 4.远程仓库

托管代码的服务器（如 GitHub、GitLab），用于团队协作

### Kafka

#### 组件

1. **Producer（生产者）**：负责向 Kafka 发送消息。

2. **Consumer（消费者）**：负责从 Kafka 读取消息。

3. **Broker（代理）**：Kafka 服务器节点，存储和管理消息数据。

4. **Topic（主题）**：消息的分类单位，Producer 将消息写入特定 Topic，Consumer 从 Topic 读取消息。

5. **Partition（分区）**：Topic 被分成多个 Partition，实现并行读写和高吞吐量。每个分区有个leader，它是这个partition数据的唯一入口，所有写入该partition的消息，都会先发送到leader，leader会将自己收到数据同步给follower（副本），follower也会一直从leader拉去消息，保持数据一致性

6. **Offset（偏移量）**：Kafka 为每个消息分配的唯一标识，用于 Consumer 追踪读取进度。

7. Zookeeper：用于管理 Kafka 集群的元数据、Leader 选举等。

#### 生产者

1. 生产者通过轮询的方式先择partition，也可以自定义分区策略

2. 也可以指定key（通过哈希计算），相同的key写入同一分区

3. 生产者如何保证消息发送成功？

**acks=0**：不等待确认，性能高但可能丢消息。

**acks=1**：Leader 收到数据后确认，可能丢失副本同步未完成的数据。

**acks=all**：所有副本同步后才确认，最安全但吞吐量较低。

#### 消费者

1\. Kafka 消费者如何保证消息的顺序性？**单分区消费时**：Kafka 能保证消息顺序。**多个分区时**：不能保证全局顺序，但能保证 **同一 Key** 的消息进入同一分区，从而保证 Key 级别的顺序性。

2\. 消费组（Consumer Group）如何工作？一个partition只能被一个consumer消费（同一个group内），多个消费组可以并行消费同一个topic

#### 性能优化

1. 生产者：批量发送，数据压缩，异步发送，调节配置参数

2. 消费者：多线程消费，批量拉取，调优offset提交策略，调节配置参数

## 生产环境中如何排查内存问题

### **1. 监控与报警（预防性措施）**

#### **实时监控工具**

- ##### **系统级监控**：

  - `top`/`htop`：观察进程内存（RES/VIRT）增长趋势。
  - `smem`/`pmap`：分析进程内存分布（如堆、栈、共享内存）。
  - `/proc/<pid>/status`：查看进程的详细内存统计（`VmRSS`为实际物理内存占用）。

- ##### **容器化环境**：

  - 使用Prometheus + Grafana监控容器内存限制（`cgroup`）与实际使用量。
  - 设置报警规则，当内存超过阈值时触发通知。

#### **应用级监控**

- ##### **嵌入内存统计代码**：

  ```c++
  #include <malloc.h>
  void log_memory_usage() {
    struct mallinfo mi = mallinfo();
    // 记录堆内存使用量（单位：KB）
    log("Heap used: %d KB", mi.uordblks / 1024);
  }
  ```

- **周期性输出日志**：定时调用`log_memory_usage()`，观察内存增长模式。

------

### **2. 低侵入性工具**

#### **TCMalloc/Jemalloc 堆分析**

- **编译时替换默认分配器**：

```shell
# 使用TCMalloc
  -ltcmalloc
```

- **运行时获取堆快照**：

```shell
# 导出当前堆分配信息
  HEAPPROFILE=/tmp/heap_profile ./your_program
# 使用pprof分析
  pprof --svg ./your_program /tmp/heap_profile.0001.heap > heap.svg
```

- **对比快照**：多次导出堆快照，分析未释放内存的分配路径。

#### **AddressSanitizer（ASan）的生产适配**

- **轻量级模式**（需权衡性能）：

```shell
# 开启ASan且不终止进程（适合后台服务）
  export ASAN_OPTIONS=halt_on_error=0:log_path=/tmp/asan.log
./your_program
```

------

### **3. 动态追踪技术**

#### **eBPF/BCC 工具集**

- **memleak**：跟踪未释放的内存块（内核4.1+）：

```shell
# 跟踪所有大小超过1KB的未释放内存
  memleak-bpfcc -p <pid> --top 10 -a 1024
```

- **示例输出**：

```shell
[14:32:01] Top 10 stacks with outstanding allocations:
    5120 bytes in 2 allocations from stack
    operator new(unsigned long)+0x1a [my_program]
      MyClass::allocateBuffer()+0x25 [my_program]
      main+0x47 [my_program]
```

#### **SystemTap（Linux内核追踪）**

- 脚本示例：跟踪`malloc`/`free`调用：

```shell
probe process("my_program").function("malloc") { log("malloc: " . size) }
  probe process("my_program").function("free")   { log("free: " . ptr) }
```

------

### **4. 核心转储（Core Dump）分析**

#### **生成Core Dump**

- **手动触发**（无需终止进程）：

```shell
gcore <pid>  # 生成核心转储文件（如core.<pid>）
```

- **自动配置**：

```shell
ulimit -c unlimited          # 允许生成core文件
sysctl -w kernel.core_pattern=/tmp/core-%e-%p  # 指定保存路径
```

#### **使用GDB分析**

- **加载Core文件**：

```shell
gdb ./your_program /tmp/core.1234
```

- **查看内存分配**：

```shell
(gdb) info proc mappings    # 查看内存映射
(gdb) malloc_info           # 显示堆信息（需glibc支持）
```

------

### **5. 灰度与增量排查**

#### **分阶段发布**

- **A/B测试**：仅对部分节点更新代码，观察内存变化。
- **回滚机制**：若新版本内存异常，快速回退到稳定版本。

#### **代码热修复**

- **动态库替换**：通过`dlopen`/`dlsym`动态加载修复后的逻辑（需提前设计插件架构）。

------

### **6. 生产环境代码级优化**

#### **关键点**

- **避免裸指针**：全面使用`std::unique_ptr`/`std::shared_ptr`。

- **资源池化**：对频繁申请/释放的对象使用对象池（如Boost.Pool）。

- **泄漏模式检查**：

```c++
// 在析构函数中验证资源释放
  ~MyClass() {
  if (buffer_ != nullptr) { 
      log_error("Buffer not released!"); 
      // 生产环境可标记异常但不崩溃
    }
  }
```

------

### **7. 应急方案**

- **重启策略**：
  - 配置看门狗（watchdog），在内存超限时自动重启进程。
  - 使用容器编排工具（如Kubernetes）设置内存Limit，触发OOM时自动重建Pod。
- **降级处理**：关闭非核心功能，减少内存压力。

------

### **示例：TCMalloc堆分析输出**

```shell
Total: 15.3 MB
 10.2 MB (66.7%) in 2048 allocations from @ 0x401234 in MyClass::processRequest
  5.1 MB (33.3%) in 512 allocations from @ 0x402345 in NetworkModule::sendData
```

- **结论**：`MyClass::processRequest`函数存在未释放的内存分配。

------

### **总结**

- **监控先行**：建立内存基线，识别异常增长模式。
- **低侵入工具**：优先使用TCMalloc/eBPF，避免影响服务。
- **核心转储**：在可控时间内捕获现场数据。
- **防御性编码**：通过智能指针和资源池减少泄漏可能性。
